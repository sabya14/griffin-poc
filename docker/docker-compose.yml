version: '2.2'
services:

  # MONGO AND SEED

  mongodb:
    image: mongo
    ports:
      - "27017:27017"

  mongo-seed:
    build: mongo-seed
    depends_on:
      - mongodb

  # HIVE

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - hadoop-hive.env
    ports:
      - "50070:50070"

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0


  # TRINO

  coordinator:
    image: "lewuathe/trino-coordinator:${trino_VERSION}"
    ports:
      - "8080:8080"
    container_name: "coordinator"
    command: http://coordinator:8080 coordinator
    volumes:
       - ./trino/catalog:/usr/local/trino/etc/catalog

  worker0:
    image: "lewuathe/trino-worker:${trino_VERSION}"
    container_name: "worker0"
    ports:
      - "8081:8081"
    command: http://coordinator:8080 worker0
    volumes:
      - ./trino/catalog:/usr/local/trino/etc/catalog


#  # SPARK
#  spark-master:
#    image: bde2020/spark-master:2.4.5-hadoop2.7
#    container_name: spark-master
#    ports:
#      - "7077:7077"
#      - "8080:8080"
#    environment:
#      - INIT_DAEMON_STEP=setup_spark
#
#  spark-worker-1:
#    image: bde2020/spark-worker:2.4.5-hadoop2.7
#    container_name: spark-worker-1
#    restart: always
#    depends_on:
#      - spark-master
#    ports:
#      - "8081:8081"
#    environment:
#      - "SPARK_MASTER=spark://spark-master:7077"


volumes:
  namenode:
  datanode: